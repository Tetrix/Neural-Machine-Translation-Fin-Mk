{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import re\n",
    "import pickle\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(str, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mk embeddings\n",
    "# mk_embeddings = KeyedVectors.load('data/embeddings/mk_embeddings.bin')\n",
    "# mk_weights = torch.FloatTensor(mk_embeddings.wv.vectors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fi embeddings\n",
    "# fi_embeddings = KeyedVectors.load('data/embeddings/fi_embeddings.bin')\n",
    "# i_weights = torch.FloatTensor(fi_embeddings.wv.vectors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_embedding = KeyedVectors.load_word2vec_format('data/embeddings/cc.fi.300.vec', limit=500000)\n",
    "# mk_embedding = KeyedVectors.load_word2vec_format('data/embeddings/cc.mk.300.vec', limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_embeddings = load_vectors('data/embeddings/cc.mk.300.vec')\n",
    "# fi_embeddings = load_vectors('data/embeddings/cc.fi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# class Lang:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.word2index = {}\n",
    "#         self.word2count = {}\n",
    "#         self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "#         self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "#     def addSentence(self, sentence):\n",
    "# #         for word in sentence.split(' '):\n",
    "#         for word in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence):\n",
    "#             if word[0] == '-' and len(word) > 1:\n",
    "#                 self.addWord(word[1:])\n",
    "#             elif word[-1] == '-' and len(word) > 1:\n",
    "#                 self.addWord(word[:-1])\n",
    "#             else:\n",
    "#                 self.addWord(word)\n",
    "\n",
    "#     def addWord(self, word):\n",
    "#         if word not in self.word2index:\n",
    "#             if self.name == 'fin_val':\n",
    "#                 if word in fi_embeddings.wv.vocab:\n",
    "#                     embedding_index = fi_embeddings.wv.vocab[word].index\n",
    "#                 else:\n",
    "#                     fi_embeddings.wv.add(word, np.random.normal(scale=0.6, size=(300, )), replace=False)\n",
    "#                     embedding_index = fi_embeddings.wv.vocab[word].index\n",
    "                    \n",
    "#             elif self.name == 'mk_val':\n",
    "#                 if word in mk_embeddings.wv.vocab:\n",
    "#                     embedding_index = mk_embeddings.wv.vocab[word].index\n",
    "#                 else:\n",
    "#                     mk_embeddings.wv.add(word, np.random.normal(scale=0.6, size=(300, )), replace=False)\n",
    "#                     embedding_index = mk_embeddings.wv.vocab[word].index\n",
    "                    \n",
    "                    \n",
    "#             self.word2index[word] = embedding_index\n",
    "#             self.word2count[word] = 1\n",
    "#             self.index2word[embedding_index] = word\n",
    "#             self.n_words += 1\n",
    "#         else:\n",
    "#             self.word2count[word] += 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "#     s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "#     if len(p) == 1:\n",
    "#         print(p)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "#     return [lang.word2index[word[1:]] if word[0]=='-' and len(word)>1  else lang.word2index[word[1:]] for word  in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence)]\n",
    "#     lang_list = []\n",
    "#     for word in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence):\n",
    "#         if word[0] == '-' and len(word) > 1:\n",
    "#             lang_list.append(lang.word2index[word[1:]])\n",
    "#         elif word[-1] == '-' and len(word) > 1:\n",
    "#             lang_list.append(lang.word2index[word[:-1]])\n",
    "#         else:\n",
    "#             lang_list.append(lang.word2index[word])\n",
    "#     return lang_list\n",
    "\n",
    "# re.findall(r\"[\\w']+|[.,!?;]\", sentence)\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fi_embeddings.wv.vocab['mies'].index\n",
    "# # input_sentence[0].item()\n",
    "# training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(10)]\n",
    "# input_sentence, output_sentence = training_pairs[0]\n",
    "# # print(output_lang.index2word[output_sentence[7145].item()])\n",
    "# print(output_lang.word2index['пополека'])\n",
    "# print(mk_embeddings.wv.vocab['пополека'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 2392808 sentence pairs\n",
      "Counting words...\n",
      "Trimmed to 1915404 sentence pairs\n",
      "Counted words:\n",
      "fin 531025\n",
      "mk 340779\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "# input_lang, output_lang, pairs = prepareData('fin_train', 'mk_train', False)\n",
    "# input_lang, output_lang, pairs = prepareData('fin_train', 'mk_train', False)\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('fin', 'mk', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train, pairs_test = train_test_split(pairs, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_word =  max(output_lang.word2index.items(), key=operator.itemgetter(1))[0]\n",
    "# mk_max_index = output_lang.word2index[mk_word] + 1\n",
    "\n",
    "# fi_word =  max(input_lang.word2index.items(), key=operator.itemgetter(1))[0]\n",
    "# fi_max_index = input_lang.word2index[fi_word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "    # sort a list by sequence length\n",
    "    list_of_samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    input_seqs, output_seqs = zip(*list_of_samples)\n",
    "    input_seq_lengths = [len(seq) for seq in input_seqs]\n",
    "    output_seq_lengths = [len(seq) for seq in output_seqs]\n",
    "\n",
    "    padding_value = 0\n",
    "    \n",
    "    pad_input_seqs = pad_sequence(input_seqs, batch_first=False, padding_value=padding_value)\n",
    "    pad_output_seqs = []\n",
    "    for i in output_seqs:\n",
    "        padded = i.new_zeros(max(output_seq_lengths) - i.size(0))\n",
    "        pad_output_seqs.append(torch.cat((i, padded.view(-1, 1)), dim=0))\n",
    "    \n",
    "    pad_output_seqs = torch.stack(pad_output_seqs)\n",
    "    pad_output_seqs = pad_output_seqs.permute(1, 0, 2)\n",
    "\n",
    "    return pad_input_seqs, input_seq_lengths, pad_output_seqs, output_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, dropout_p=0.2, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(fi_weights)\n",
    "#         self.embedding.requires_grad = True\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=True\n",
    "                         )\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        embedded = self.embedding(pad_seqs).squeeze(dim=2)\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs = pad_packed_sequence(outputs)[0]\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return (torch.zeros(2*self.num_layers, batch_size, self.hidden_size, device=device), torch.zeros(2*self.num_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_dictionary_size, dropout_p=0.2, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_dictionary_size, hidden_size)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(mk_weights)\n",
    "#         self.embedding.requires_grad = True\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=False\n",
    "                         )\n",
    "        self.lin = nn.Linear(hidden_size, output_dictionary_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, hidden, pad_target_seqs=None, teacher_forcing=False):\n",
    "        batch_size = hidden[1].size(1)\n",
    "        prev_word = torch.tensor(SOS_token * np.ones((1, batch_size)), device=device, dtype=torch.int64)\n",
    "        max_length = pad_target_seqs.size(0) if pad_target_seqs is not None else MAX_LENGTH\n",
    "        outputs = []\n",
    "        for t in range(max_length):\n",
    "            prev_word = prev_word.view(1, -1)\n",
    "            output = self.embedding(prev_word)\n",
    "            output, hidden = self.lstm(output, hidden)\n",
    "            output = self.softmax(self.lin(output))\n",
    "    \n",
    "            outputs.append(output)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                prev_word = pad_target_seqs[t]\n",
    "            else:\n",
    "                topv, topi = output[0, :].topk(1)\n",
    "                prev_word = topi.squeeze().detach()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        return outputs, hidden\n",
    "\n",
    "#     def init_hidden(self, batch_size, device=device):\n",
    "#         return torch.zeros(1*self.num_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "# hidden_size = 300\n",
    "encoder = Encoder(input_lang.n_words, hidden_size, dropout_p=0.2).to(device)\n",
    "decoder = Decoder(hidden_size, output_lang.n_words, dropout_p=0.2).to(device)\n",
    "# encoder = Encoder(fi_max_index, hidden_size, dropout_p=0.3).to(device)\n",
    "# decoder = Decoder(hidden_size, mk_max_index, dropout_p=0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(reduction='none')\n",
    "\n",
    "def compute_loss(decoder_outputs, pad_target_seqs, padding_value=0):  \n",
    "    n = 0\n",
    "    loss = 0\n",
    "    for i in range(decoder_outputs.shape[1]):\n",
    "        p_arr = []\n",
    "        t_arr = []\n",
    "        p = decoder_outputs[:, i, :]\n",
    "        t = pad_target_seqs[:, i].squeeze()\n",
    "        for word in range(len(t)):\n",
    "            if t[word] != padding_value:\n",
    "                p_arr.append(p[word])\n",
    "                t_arr.append(t[word])\n",
    "                n += 1\n",
    "        p_arr = torch.stack(p_arr)\n",
    "        t_arr = torch.stack(t_arr)\n",
    "        loss += criterion(p_arr, t_arr).sum()\n",
    "    loss = loss / n\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [tensorsFromPair(random.choice(pairs_train)) for i in range(10)]        \n",
    "pairs_batch_train = DataLoader(dataset=training_pairs,\n",
    "                 batch_size=128,\n",
    "                 shuffle=True,\n",
    "                 collate_fn=collate,\n",
    "                 pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss: 6.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f6860cf4be0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 715, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 1GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-755317154273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_target_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_target_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-56e2557c80c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, pad_target_seqs, teacher_forcing)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprev_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 1GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "if skip_training == False:\n",
    "    for epoch in range(n_epochs):\n",
    "        testing_pairs = [tensorsFromPair(random.choice(pairs_test)) for i in range(1000)]\n",
    "        pairs_batch_test = DataLoader(dataset=testing_pairs,\n",
    "                 batch_size=128,\n",
    "                 shuffle=True,\n",
    "                 collate_fn=collate,\n",
    "                 pin_memory=True)\n",
    "\n",
    "        complete_loss = 0\n",
    "        for i, batch in enumerate(pairs_batch_train):\n",
    "            pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # Encode input sequence\n",
    "            _, encoder_hidden = encoder(pad_input_seqs, input_seq_lengths, encoder_hidden)\n",
    "            # Decode using target sequence for teacher forcing\n",
    "            decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "#             decoder_hidden = decoder_hidden[None, :, :]\n",
    "#             decoder_hidden = torch.mean(decoder_hidden[0], 0)[0]\n",
    "#             teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                teacher_forcing = True\n",
    "            else:\n",
    "                teacher_forcing = False\n",
    "                \n",
    "            decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs, teacher_forcing=teacher_forcing)\n",
    "            loss = compute_loss(decoder_outputs, pad_target_seqs, padding_value=0)\n",
    "            loss.backward()\n",
    "            \n",
    "            complete_loss += loss\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "        print('[Epoch: %d] loss: %.4f' % (epoch + 1, complete_loss / len(pairs_batch_train)))\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(complete_loss.item() / len(pairs_batch_train)) + '\\n')  \n",
    "            \n",
    "        test_loss = 0\n",
    "        for i, batch in enumerate(pairs_batch_test):\n",
    "            pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "\n",
    "            # Encode input sequence\n",
    "            _, encoder_hidden = encoder(pad_input_seqs, input_seq_lengths, encoder_hidden)\n",
    "            # Decode using target sequence for teacher forcing\n",
    "            decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "\n",
    "            decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs, teacher_forcing=False)\n",
    "            loss = compute_loss(decoder_outputs, pad_target_seqs, padding_value=0)\n",
    "            test_loss += loss\n",
    "            \n",
    "        print('[Epoch: %d] test loss: %.4f' % (epoch + 1, test_loss / len(pairs_batch_test)))\n",
    "        with open(\"test_loss.txt\", \"a\") as f:\n",
    "            f.write(str(test_loss.item() / len(pairs_batch_test)) + '\\n')\n",
    "        \n",
    "            \n",
    "        torch.save(encoder, 'model/encoder')\n",
    "        torch.save(decoder, 'model/decoder')\n",
    "    \n",
    "    print('Final loss is: %f' % (complete_loss.item() / len(pairs_batch_train)))\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if skip_training == False:\n",
    "    torch.save(encoder, 'model/encoder')\n",
    "    torch.save(decoder, 'model/decoder')\n",
    "else:\n",
    "    encoder = torch.load('model/encoder')\n",
    "    encoder.eval()\n",
    "    \n",
    "    decoder = torch.load('model/decoder')\n",
    "    decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_seq):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_seq.size(0)\n",
    "        batch_size = 1\n",
    "\n",
    "        encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "        input_seq = input_seq.view(-1, 1, 1).to(device)\n",
    "        encoder_output, encoder_hidden = encoder(input_seq, [input_length], encoder_hidden)\n",
    "\n",
    "        decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "        decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs=None, teacher_forcing=False)\n",
    "\n",
    "        output_seq = []\n",
    "        for t in range(decoder_outputs.size(0)):\n",
    "            topv, topi = decoder_outputs[t].data.topk(1)\n",
    "            output_seq.append(topi.item())\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on training data:\n",
      "-----------------------------\n",
      "> entä aukio? EOS\n",
      "= а сквер? EOS\n",
      "< не EOS\n",
      "\n",
      "> saat vielä osasi . tulkaahan, tytöt. EOS\n",
      "= ќе си го добиете.ајде девојки. EOS\n",
      "< да, да EOS\n",
      "\n",
      "> kaikki on ollut sekaisin cassien tultua tänne. EOS\n",
      "= откако дојде кеси настана хаос. EOS\n",
      "< да, да EOS\n",
      "\n",
      "> entä aukio? EOS\n",
      "= а сквер? EOS\n",
      "< не EOS\n",
      "\n",
      "> laita se pois. EOS\n",
      "= врати го. EOS\n",
      "< не EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate random sentences from the training set\n",
    "print('\\nEvaluate on training data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    input_sentence, target_sentence = training_pairs[np.random.choice(len(training_pairs))]\n",
    "    print('>', ' '.join(input_lang.index2word[i.item()] for i in input_sentence))\n",
    "    print('=', ' '.join(output_lang.index2word[i.item()] for i in target_sentence))\n",
    "    output_sentence = evaluate(input_sentence)\n",
    "    print('<', ' '.join(output_lang.index2word[i] for i in output_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference = [['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']]\n",
    "# candidate = ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "# score = sentence_bleu(reference, candidate)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(input_seq, target_seq):\n",
    "    reference = []\n",
    "    candidate = []\n",
    "    \n",
    "    input_sentence = evaluate(input_seq)\n",
    "    target_sentence = evaluate(target_seq)\n",
    "    \n",
    "    for word in input_sentence:\n",
    "        reference.append(word)\n",
    "    \n",
    "    for word in target_sentence:\n",
    "        candidate.append(word)\n",
    "    \n",
    "    reference = [reference]\n",
    "    \n",
    "    return sentence_bleu(reference, candidate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
