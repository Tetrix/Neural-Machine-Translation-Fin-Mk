{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import re\n",
    "import pickle\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(str, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 2392808 sentence pairs\n",
      "Counting words...\n",
      "Trimmed to 1915404 sentence pairs\n",
      "Counted words:\n",
      "fin 531025\n",
      "mk 340779\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('fin', 'mk', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train, pairs_test = train_test_split(pairs, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "    # sort a list by sequence length\n",
    "    list_of_samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    input_seqs, output_seqs = zip(*list_of_samples)\n",
    "    input_seq_lengths = [len(seq) for seq in input_seqs]\n",
    "    output_seq_lengths = [len(seq) for seq in output_seqs]\n",
    "\n",
    "    padding_value = 0\n",
    "    \n",
    "    pad_input_seqs = pad_sequence(input_seqs, batch_first=False, padding_value=padding_value)\n",
    "    pad_output_seqs = []\n",
    "    for i in output_seqs:\n",
    "        padded = i.new_zeros(max(output_seq_lengths) - i.size(0))\n",
    "        pad_output_seqs.append(torch.cat((i, padded.view(-1, 1)), dim=0))\n",
    "    \n",
    "    pad_output_seqs = torch.stack(pad_output_seqs)\n",
    "    pad_output_seqs = pad_output_seqs.permute(1, 0, 2)\n",
    "\n",
    "    return pad_input_seqs, input_seq_lengths, pad_output_seqs, output_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, dropout_p=0.2, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=True\n",
    "                         )\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        embedded = self.embedding(pad_seqs).squeeze(dim=2)\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs = pad_packed_sequence(outputs)[0]\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return (torch.zeros(2*self.num_layers, batch_size, self.hidden_size, device=device), torch.zeros(2*self.num_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_dictionary_size, dropout_p=0.2, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_dictionary_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=False\n",
    "                         )\n",
    "        self.lin = nn.Linear(hidden_size, output_dictionary_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, hidden, pad_target_seqs=None, teacher_forcing=False):\n",
    "        batch_size = hidden[1].size(1)\n",
    "        prev_word = torch.tensor(SOS_token * np.ones((1, batch_size)), device=device, dtype=torch.int64)\n",
    "        max_length = pad_target_seqs.size(0) if pad_target_seqs is not None else MAX_LENGTH\n",
    "        outputs = []\n",
    "        for t in range(max_length):\n",
    "            prev_word = prev_word.view(1, -1)\n",
    "            output = self.embedding(prev_word)\n",
    "            output, hidden = self.lstm(output, hidden)\n",
    "            output = self.softmax(self.lin(output))\n",
    "    \n",
    "            outputs.append(output)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                prev_word = pad_target_seqs[t]\n",
    "            else:\n",
    "                topv, topi = output[0, :].topk(1)\n",
    "                prev_word = topi.squeeze().detach()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_checkpoint == True:\n",
    "#     encoder_checkpoint = torch.load('model/encoder_opt', map_location=\"cuda:0\")\n",
    "#     decoder_checkpoint = torch.load('model/decoder_opt', map_location=\"cuda:0\")\n",
    "\n",
    "    encoder_checkpoint = torch.load('model_test/encoder_opt', map_location=\"cuda:0\")\n",
    "    decoder_checkpoint = torch.load('model_test/decoder_opt', map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = Encoder(input_lang.n_words, hidden_size, dropout_p=0.2).to(device)\n",
    "decoder = Decoder(hidden_size, output_lang.n_words, dropout_p=0.2).to(device)\n",
    "\n",
    "if restore_checkpoint == True:\n",
    "    encoder.load_state_dict(encoder_checkpoint['model_state_dict'], )\n",
    "    decoder.load_state_dict(decoder_checkpoint['model_state_dict'])\n",
    "\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(reduction='none')\n",
    "\n",
    "def compute_loss(decoder_outputs, pad_target_seqs, padding_value=0):  \n",
    "    n = 0\n",
    "    loss = 0\n",
    "    for i in range(decoder_outputs.shape[1]):\n",
    "        p_arr = []\n",
    "        t_arr = []\n",
    "        p = decoder_outputs[:, i, :]\n",
    "        t = pad_target_seqs[:, i].squeeze()\n",
    "        for word in range(len(t)):\n",
    "            if t[word] != padding_value:\n",
    "                p_arr.append(p[word])\n",
    "                t_arr.append(t[word])\n",
    "                n += 1\n",
    "        p_arr = torch.stack(p_arr)\n",
    "        t_arr = torch.stack(t_arr)\n",
    "        loss += criterion(p_arr, t_arr).sum()\n",
    "    loss = loss / n\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "# decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.01)\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_checkpoint == True:\n",
    "    encoder_optimizer.load_state_dict(encoder_checkpoint['optimizer'])\n",
    "    decoder_optimizer.load_state_dict(decoder_checkpoint['optimizer'])\n",
    "    \n",
    "    for state in encoder_optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.cuda()\n",
    "\n",
    "    for state in decoder_optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [tensorsFromPair(random.choice(pairs_train)) for i in range(20000)]        \n",
    "pairs_batch_train = DataLoader(dataset=training_pairs,\n",
    "                 batch_size=64,\n",
    "                 shuffle=True,\n",
    "                 collate_fn=collate,\n",
    "                 pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if skip_training == False:\n",
    "    for epoch in range(n_epochs):\n",
    "        testing_pairs = [tensorsFromPair(random.choice(pairs_test)) for i in range(500)]\n",
    "        pairs_batch_test = DataLoader(dataset=testing_pairs,\n",
    "                 batch_size=64,\n",
    "                 shuffle=True,\n",
    "                 collate_fn=collate,\n",
    "                 pin_memory=True)\n",
    "\n",
    "        complete_loss = 0\n",
    "        for i, batch in enumerate(pairs_batch_train):\n",
    "            pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # Encode input sequence\n",
    "            _, encoder_hidden = encoder(pad_input_seqs, input_seq_lengths, encoder_hidden)\n",
    "            # Decode using target sequence for teacher forcing\n",
    "            decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                teacher_forcing = True\n",
    "            else:\n",
    "                teacher_forcing = False\n",
    "                \n",
    "            decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs, teacher_forcing=teacher_forcing)\n",
    "            loss = compute_loss(decoder_outputs, pad_target_seqs, padding_value=0)\n",
    "            loss.backward()\n",
    "            \n",
    "            complete_loss += loss\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            \n",
    "        print('[Epoch: %d] loss: %.4f' % (epoch + 1, complete_loss / len(pairs_batch_train)))\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(complete_loss.item() / len(pairs_batch_train)) + '\\n')  \n",
    "            \n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(pairs_batch_test):\n",
    "                pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "                batch_size = pad_input_seqs.size(1)\n",
    "                pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "                encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "\n",
    "                # Encode input sequence\n",
    "                _, encoder_hidden = encoder(pad_input_seqs, input_seq_lengths, encoder_hidden)\n",
    "                # Decode using target sequence for teacher forcing\n",
    "                decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "\n",
    "                decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs, teacher_forcing=False)\n",
    "                loss = compute_loss(decoder_outputs, pad_target_seqs, padding_value=0)\n",
    "                test_loss += loss\n",
    "\n",
    "            print('[Epoch: %d] test loss: %.4f' % (epoch + 1, test_loss / len(pairs_batch_test)))\n",
    "            with open(\"test_loss.txt\", \"a\") as f:\n",
    "                f.write(str(test_loss.item() / len(pairs_batch_test)) + '\\n')\n",
    "        \n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:     \n",
    "            state = {'epoch': epoch + 1, 'state_dict': encoder.state_dict(),\n",
    "                 'optimizer': encoder_optimizer.state_dict(), 'model_state_dict': encoder.state_dict()}\n",
    "            torch.save(state, 'model/encoder_opt')\n",
    "\n",
    "            state = {'epoch': epoch + 1, 'state_dict': decoder.state_dict(),\n",
    "                 'optimizer': decoder_optimizer.state_dict(), 'model_state_dict': decoder.state_dict()}\n",
    "            torch.save(state, 'model/decoder_opt')\n",
    "\n",
    "            torch.save(encoder, 'model/encoder')\n",
    "            torch.save(decoder, 'mode/decoder')\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if skip_training == False:\n",
    "    torch.save(encoder, 'model/encoder')\n",
    "    torch.save(decoder, 'model/decoder')\n",
    "else:\n",
    "    encoder = torch.load('model_test/encoder')\n",
    "    encoder.eval()\n",
    "    \n",
    "    decoder = torch.load('model_test/decoder')\n",
    "    decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_seq):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_seq.size(0)\n",
    "        batch_size = 1\n",
    "\n",
    "        encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "        input_seq = input_seq.view(-1, 1, 1).to(device)\n",
    "        encoder_output, encoder_hidden = encoder(input_seq, [input_length], encoder_hidden)\n",
    "\n",
    "        decoder_hidden = (encoder_hidden[0].mean(0, keepdim=True),encoder_hidden[1].mean(0, keepdim=True))\n",
    "        decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs=None, teacher_forcing=False)\n",
    "\n",
    "        output_seq = []\n",
    "        for t in range(decoder_outputs.size(0)):\n",
    "            topv, topi = decoder_outputs[t].data.topk(1)\n",
    "            output_seq.append(topi.item())\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on training data:\n",
      "-----------------------------\n",
      "> en vieläkään näe sinua. EOS\n",
      "= се уште не те гледам. EOS\n",
      "< не не да да EOS\n",
      "\n",
      "> he tietävät jo kaiken. EOS\n",
      "= тие веќе знаат се. EOS\n",
      "< ти си дека ќе ни застанеш на работа. EOS\n",
      "\n",
      "> oletko nähnyt ediiliä? EOS\n",
      "= едилот . сте го виделе ли едилот? EOS\n",
      "< дали си си! EOS\n",
      "\n",
      "> olet hyvin innokas tanssija. EOS\n",
      "= ти си многу ентузијастички танцувач. EOS\n",
      "< ти си го на EOS\n",
      "\n",
      "> hän tunkeutui sisälle. EOS\n",
      "= ме турна внатре. EOS\n",
      "< слушај, фреди. EOS\n",
      "\n",
      "> hän ymmärtää nyt. EOS\n",
      "= но  сега разбра. EOS\n",
      "< штета што почнувам. EOS\n",
      "\n",
      "> se on vain EOS\n",
      "= само EOS\n",
      "< тоа е е EOS\n",
      "\n",
      "> sanon, että ne jotka täällä rukoilevat, tuhlaavat aikaansa. EOS\n",
      "= тие што се молат овде, го трошат само времето. EOS\n",
      "< најдете ја однеле опремата во леглото на дракула. EOS\n",
      "\n",
      "> kiitos, varakuvernööri. EOS\n",
      "= благодарам, заменик губернаторе. EOS\n",
      "< одел од велшаните! EOS\n",
      "\n",
      "> mies nimeltä shawn fentress oli siinä junassa. EOS\n",
      "= човекот по име шон фентрес беше на тој воз. EOS\n",
      "< тој ли е да како болново копиле? EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate random sentences from the training set\n",
    "print('\\nEvaluate on training data:')\n",
    "print('-----------------------------')\n",
    "for i in range(10):\n",
    "    input_sentence, target_sentence = training_pairs[np.random.choice(len(training_pairs))]\n",
    "    print('>', ' '.join(input_lang.index2word[i.item()] for i in input_sentence))\n",
    "    print('=', ' '.join(output_lang.index2word[i.item()] for i in target_sentence))\n",
    "    output_sentence = evaluate(input_sentence)\n",
    "    print('<', ' '.join(output_lang.index2word[i] for i in output_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_BLEU(pairs_test):\n",
    "    testing_pairs = [tensorsFromPair(pairs_test[i]) for i in range(int(len(pairs_test)/100))]\n",
    "    bleu_score = 0\n",
    "    for i in range(len(testing_pairs)):\n",
    "        input_sentence, target_sentence = testing_pairs[i]    \n",
    "        reference = []\n",
    "        candidate = []\n",
    "        for word in target_sentence:\n",
    "            if output_lang.index2word[word.item()] != 'EOS':\n",
    "                reference.append(output_lang.index2word[word.item()])\n",
    "\n",
    "        output_sentence = evaluate(input_sentence)\n",
    "        for word in output_sentence:\n",
    "            if output_lang.index2word[word] != 'EOS':\n",
    "                candidate.append(output_lang.index2word[word])\n",
    "\n",
    "        bleu_score += sentence_bleu([reference], candidate)\n",
    "    return bleu_score / int(len(pairs_test)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4284661985472901e-80"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_BLEU(pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss():\n",
    "    train_loss = []\n",
    "    with open('loss.txt', 'r') as f:\n",
    "        for row in f:\n",
    "            train_loss.append(float(row.rstrip('\\n')))\n",
    "\n",
    "    test_loss = []\n",
    "    with open('test_loss.txt', 'r') as f:\n",
    "        for row in f:\n",
    "            test_loss.append(float(row.rstrip('\\n')))\n",
    "\n",
    "    epochs = np.arange(1, 31, 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss)\n",
    "    plt.plot(epochs, test_loss)\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss comparison')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
