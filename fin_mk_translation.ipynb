{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import re\n",
    "import pickle\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(str, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mk embeddings\n",
    "mk_embeddings = KeyedVectors.load('data/embeddings/mk_embeddings.bin')\n",
    "mk_weights = torch.FloatTensor(mk_embeddings.wv.vectors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fi embeddings\n",
    "fi_embeddings = KeyedVectors.load('data/embeddings/fi_embeddings.bin')\n",
    "fi_weights = torch.FloatTensor(fi_embeddings.wv.vectors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_embeddings['-abigailiin.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_embedding = KeyedVectors.load_word2vec_format('data/embeddings/cc.fi.300.vec', limit=500000)\n",
    "# mk_embedding = KeyedVectors.load_word2vec_format('data/embeddings/cc.mk.300.vec', limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_embeddings = load_vectors('data/embeddings/cc.mk.300.vec')\n",
    "# fi_embeddings = load_vectors('data/embeddings/cc.fi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "#         for word in sentence.split(' '):\n",
    "        for word in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence):\n",
    "            if word[0] == '-' and len(word) > 1:\n",
    "                self.addWord(word[1:])\n",
    "            elif word[-1] == '-' and len(word) > 1:\n",
    "                self.addWord(word[:-1])\n",
    "            else:\n",
    "                self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            if self.name == 'fin_t':\n",
    "                if word in fi_embeddings.wv.vocab:\n",
    "                    embedding_index = fi_embeddings.wv.vocab[word].index\n",
    "                else:\n",
    "                    fi_embeddings.wv.add(word, np.random.normal(scale=0.6, size=(300, )), replace=False)\n",
    "                    embedding_index = fi_embeddings.wv.vocab[word].index\n",
    "                    \n",
    "            elif self.name == 'mk_t':\n",
    "                if word in mk_embeddings.wv.vocab:\n",
    "                    embedding_index = mk_embeddings.wv.vocab[word].index\n",
    "                else:\n",
    "                    mk_embeddings.wv.add(word, np.random.normal(scale=0.6, size=(300, )), replace=False)\n",
    "                    embedding_index = mk_embeddings.wv.vocab[word].index\n",
    "                    \n",
    "                    \n",
    "            self.word2index[word] = embedding_index\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[embedding_index] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "#     s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "#     if len(p) == 1:\n",
    "#         print(p)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "#     return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "#     return [lang.word2index[word[1:]] if word[0]=='-' and len(word)>1  else lang.word2index[word[1:]] for word  in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence)]\n",
    "    lang_list = []\n",
    "    for word in re.findall(r\"[\\w'-]+|[.,!?;]\", sentence):\n",
    "        if word[0] == '-' and len(word) > 1:\n",
    "            lang_list.append(lang.word2index[word[1:]])\n",
    "        elif word[-1] == '-' and len(word) > 1:\n",
    "            lang_list.append(lang.word2index[word[:-1]])\n",
    "        else:\n",
    "            lang_list.append(lang.word2index[word])\n",
    "    return lang_list\n",
    "\n",
    "# re.findall(r\"[\\w']+|[.,!?;]\", sentence)\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fi_embeddings.wv.vocab['mies'].index\n",
    "# # input_sentence[0].item()\n",
    "# training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(10)]\n",
    "# input_sentence, output_sentence = training_pairs[0]\n",
    "# # print(output_lang.index2word[output_sentence[7145].item()])\n",
    "# print(output_lang.word2index['пополека'])\n",
    "# print(mk_embeddings.wv.vocab['пополека'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 29 sentence pairs\n",
      "Counting words...\n",
      "Trimmed to 24 sentence pairs\n",
      "Counted words:\n",
      "fin_t 95\n",
      "mk_t 94\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "# input_lang, output_lang, pairs = prepareData('fin_train', 'mk_train', False)\n",
    "input_lang, output_lang, pairs = prepareData('fin_t', 'mk_t', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_word =  max(output_lang.word2index.items(), key=operator.itemgetter(1))[0]\n",
    "mk_max_index = output_lang.word2index[mk_word] + 1\n",
    "\n",
    "fi_word =  max(input_lang.word2index.items(), key=operator.itemgetter(1))[0]\n",
    "fi_max_index = input_lang.word2index[fi_word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "    # sort a list by sequence length\n",
    "    list_of_samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    input_seqs, output_seqs = zip(*list_of_samples)\n",
    "    input_seq_lengths = [len(seq) for seq in input_seqs]\n",
    "    output_seq_lengths = [len(seq) for seq in output_seqs]\n",
    "\n",
    "    padding_value = 0\n",
    "    \n",
    "    pad_input_seqs = pad_sequence(input_seqs, batch_first=False, padding_value=padding_value)\n",
    "    pad_output_seqs = []\n",
    "    for i in output_seqs:\n",
    "        padded = i.new_zeros(max(output_seq_lengths) - i.size(0))\n",
    "        pad_output_seqs.append(torch.cat((i, padded.view(-1, 1)), dim=0))\n",
    "    \n",
    "    pad_output_seqs = torch.stack(pad_output_seqs)\n",
    "    pad_output_seqs = pad_output_seqs.permute(1, 0, 2)\n",
    "\n",
    "    return pad_input_seqs, input_seq_lengths, pad_output_seqs, output_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, dropout_p=0.2, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "#         self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(fi_weights)\n",
    "        self.embedding.requires_grad = True\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=True\n",
    "                         )\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        embedded = self.embedding(pad_seqs).squeeze(dim=2)\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed)\n",
    "        outputs = pad_packed_sequence(outputs)[0]\n",
    "        return outputs, hidden[0]\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return torch.zeros(2*self.num_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_dictionary_size, dropout_p=0.2, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "#         self.embedding = nn.Embedding(output_dictionary_size, hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(mk_weights)\n",
    "        self.embedding.requires_grad = True\n",
    "        self.lstm = nn.LSTM(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers=self.num_layers,\n",
    "                          bidirectional=False\n",
    "                         )\n",
    "        self.out = nn.Linear(hidden_size, output_dictionary_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, hidden, pad_target_seqs=None, teacher_forcing=False):\n",
    "        batch_size = hidden.size(1)\n",
    "        prev_word = torch.tensor(SOS_token * np.ones((1, batch_size)), device=device, dtype=torch.int64)\n",
    "        max_length = pad_target_seqs.size(0) if pad_target_seqs is not None else MAX_LENGTH\n",
    "        outputs = []\n",
    "        for t in range(max_length):\n",
    "            prev_word = prev_word.view(1, -1)\n",
    "            output = self.embedding(prev_word)\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.lstm(output)\n",
    "            output = self.softmax(self.out(output))\n",
    "    \n",
    "            outputs.append(output)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                prev_word = pad_target_seqs[t]\n",
    "            else:\n",
    "                topv, topi = output[0, :].topk(1)\n",
    "                prev_word = topi.squeeze().detach()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        return outputs, hidden[0]\n",
    "\n",
    "    def init_hidden(self, batch_size, device=device):\n",
    "        return torch.zeros(1*self.num_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size = 256\n",
    "hidden_size = 300\n",
    "# encoder = Encoder(input_lang.n_words, hidden_size, dropout_p=0.5).to(device)\n",
    "# decoder = Decoder(hidden_size, output_lang.n_words, dropout_p=0.5).to(device)\n",
    "encoder = Encoder(fi_max_index, hidden_size, dropout_p=0.2).to(device)\n",
    "decoder = Decoder(hidden_size, mk_max_index, dropout_p=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(reduction='none')\n",
    "\n",
    "def compute_loss(decoder_outputs, pad_target_seqs, padding_value=0):  \n",
    "    n = 0\n",
    "    loss = 0\n",
    "    for i in range(decoder_outputs.shape[1]):\n",
    "        p_arr = []\n",
    "        t_arr = []\n",
    "        p = decoder_outputs[:, i, :]\n",
    "        t = pad_target_seqs[:, i].squeeze()\n",
    "        for word in range(len(t)):\n",
    "            if t[word] != padding_value:\n",
    "                p_arr.append(p[word])\n",
    "                t_arr.append(t[word])\n",
    "                n += 1\n",
    "        p_arr = torch.stack(p_arr)\n",
    "        t_arr = torch.stack(t_arr)\n",
    "        loss += criterion(p_arr, t_arr).sum()\n",
    "    loss = loss / n\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss: 8.3948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/u/15/porjazd1/unix/.local/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2a576d2406b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Epoch: %d] loss: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model/encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model/decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final loss is: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if skip_training == False:\n",
    "    for epoch in range(n_epochs):\n",
    "        training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(24)]\n",
    "        \n",
    "        pairs_batch = DataLoader(dataset=training_pairs,\n",
    "                         batch_size=3,\n",
    "                         shuffle=True,\n",
    "                         collate_fn=collate,\n",
    "                         pin_memory=True)        \n",
    "        \n",
    "        for i, batch in enumerate(pairs_batch):\n",
    "            pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # Encode input sequence\n",
    "            _, encoder_hidden = encoder(pad_input_seqs, input_seq_lengths, encoder_hidden)\n",
    "\n",
    "            # Decode using target sequence for teacher forcing\n",
    "            decoder_hidden = encoder_hidden\n",
    "            teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs, teacher_forcing=teacher_forcing)\n",
    "            loss = compute_loss(decoder_outputs, pad_target_seqs, padding_value=0)\n",
    "            loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "        print('[Epoch: %d] loss: %.4f' % (epoch + 1, loss.item()))\n",
    "        torch.save(encoder, 'model/encoder')\n",
    "        torch.save(decoder, 'model/decoder')\n",
    "    \n",
    "    print('Final loss is: %f' % (loss.item()))\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True\n",
    "if skip_training == False:\n",
    "    torch.save(encoder, 'model/encoder')\n",
    "    torch.save(decoder, 'model/decoder')\n",
    "else:\n",
    "    encoder = torch.load('model/encoder')\n",
    "    encoder.eval()\n",
    "    \n",
    "    decoder = torch.load('model/decoder')\n",
    "    decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_seq):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_seq.size(0)\n",
    "        batch_size = 1\n",
    "\n",
    "        encoder_hidden = encoder.init_hidden(batch_size, device)\n",
    "        input_seq = input_seq.view(-1, 1, 1).to(device)\n",
    "        encoder_output, encoder_hidden = encoder(input_seq, [input_length], encoder_hidden)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs, decoder_hidden = decoder(decoder_hidden, pad_target_seqs=None, teacher_forcing=False)\n",
    "\n",
    "        output_seq = []\n",
    "        for t in range(decoder_outputs.size(0)):\n",
    "            topv, topi = decoder_outputs[t].data.topk(1)\n",
    "            output_seq.append(topi.item())\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on training data:\n",
      "-----------------------------\n",
      "<generator object <genexpr> at 0x7f6201da6728>\n",
      "> hän kuuluu keittiöön . hän on siivooja . ,\n",
      "= тој е чистач или слично . ,\n",
      "< го го го го го го го го го го\n",
      "\n",
      "<generator object <genexpr> at 0x7f62022185c8>\n",
      "> ette ole puhuneet viikkoihin . ,\n",
      "= немате зборувано со недели . ,\n",
      "< го го го го го го го го го го\n",
      "\n",
      "<generator object <genexpr> at 0x7f62022185c8>\n",
      "> en anna sinun pettyä . ,\n",
      "= нема да те изневерам . ,\n",
      "< го го го го го го го го го го\n",
      "\n",
      "<generator object <genexpr> at 0x7f62022185c8>\n",
      "> kuinka monta astetta ? ,\n",
      "= хелмсли ! по кој степен ? ,\n",
      "< го го го го го го го го го го\n",
      "\n",
      "<generator object <genexpr> at 0x7f62022185c8>\n",
      "> sinä ja daryl olette opettaneet minua ampumaan . ,\n",
      "= ти и дерил ме учевте како да пукам . ,\n",
      "< го го го го го го го го го го\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate random sentences from the training set\n",
    "print('\\nEvaluate on training data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    input_sentence, target_sentence = training_pairs[np.random.choice(len(training_pairs))]\n",
    "    print('>', ' '.join(input_lang.index2word[i.item()] for i in input_sentence))\n",
    "    print('=', ' '.join(output_lang.index2word[i.item()] for i in target_sentence))\n",
    "    output_sentence = evaluate(input_sentence)\n",
    "    print('<', ' '.join(output_lang.index2word[i] for i in output_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
